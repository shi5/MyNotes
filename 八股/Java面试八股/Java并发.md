
## 什么是进程和线程

### 进程

进程是程序的一次执行过程，是系统运行程序的基本单位

在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。

### 线程

线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。

同类的多个线程共享进程的**堆**和**方法区**资源，但每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**，所以系统在产生一个线程，或是在各个线程之间做切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。

## Java线程和操作系统的线程有啥区别

JDK1.2之前，Java 线程是基于绿色线程（Green Threads）实现的，这是一种用户级线程（用户线程），也就是说 JVM 自己模拟了多线程的运行，而不依赖于操作系统。

JDK1.2之后，Java 线程改为基于原生线程（Native Threads）实现，也就是说 JVM 直接使用操作系统原生的内核级线程（内核线程）来实现 Java 线程，由操作系统内核进行线程的调度和管理。

**现在的 Java 线程的本质其实就是操作系统的线程**。

>用户线程：由用户空间程序管理和调度的线程，运行在用户空间（专门给应用程序使用）。
>内核线程：由操作系统内核管理和调度的线程，运行在内核空间（只有内核程序可以访问）。

用户线程和内核线程的区别和特点：用户线程创建和切换成本低，但不可以利用多核。内核态线程，创建和切换成本高，可以利用多核。

线程模型是用户线程和内核线程之间的关联方式，常见的线程模型三种：一对一，多对一，多对多

在 Windows 和 Linux 等主流操作系统中，Java 线程采用的是一对一的线程模型，也就是一个 Java 线程对应一个系统内核线程。

## 线程和进程的关系、区别和缺点

![[Pasted image 20240326201929.png]]

一个进程中可以有多个线程，多个线程共享进程的**堆**和**方法区 (JDK1.8 之后的元空间)**资源，但是每个线程有自己的**程序计数器**、**虚拟机栈** 和 **本地方法栈**。

### 为什么程序计数器、虚拟机栈和本地方法栈是线程私有的呢？为什么堆和方法区是线程共享的呢？

#### 程序技术器为什么是私有的

程序计数器私有主要是为了**线程切换后能恢复到正确的执行位置**。

程序计数器的主要作用：
1. 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制
2. 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候可以继续运行

> 如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。

#### 虚拟机栈和本地方法栈为什么是私有的

为了**保证线程中的局部变量不被别的线程访问到**

虚拟机栈：每个 Java 方法在执行之前会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。
本地方法栈：和虚拟机栈所发挥的作用非常相似
> **虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。**

在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。

#### 堆和方法区

堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (几乎所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。

## 并行和并发的区别

- **并发**：两个及两个以上的作业在同一 **时间段** 内执行。
- **并行**：两个及两个以上的作业在同一 **时刻** 执行。

最关键的点是：是否是 **同时** 执行。

## 同步和异步的区别

- **同步**：发出一个调用之后，在没有得到结果之前， 该调用就不可以返回，一直等待。
- **异步**：调用在发出之后，不用等待返回结果，该调用直接返回。

## 为什么要使用多线程

- **从计算机底层来说**，线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。
- **从当代互联网发展趋势来说**：现在的系统并发量大，多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。


## 线程安全与线程不安全

- 线程安全指的是在多线程环境下，对于同一份数据，不管有多少个线程同时访问，都能保证这份数据的正确性和一致性。
- 线程不安全则表示在多线程环境下，对于同一份数据，多个线程同时访问时可能会导致数据混乱、错误或者丢失。

## 单核CPU运行多个程序效率一定高吗？

对于单核 CPU 来说，如果任务是 CPU 密集型的，那么开很多线程会影响效率；如果任务是 IO 密集型的，那么开很多线程会提高效率。

## Java创建线程

三种方式：
- 继承`Thread`类；
- 实现`Runnable`接口；
- 实现`Callable`接口。

严格来说，Java只有一种方式创建线程：通过`new Thread().start()`创建，不管是哪种方式，最终还是依赖于`new Thread().start()`。

>  必须调用`Thread`实例的`start()`方法才能启动新线程，直接调用`run()`方法相当于普通函数调用

## Java线程的生命周期和状态

Java的这些线程状态代表的是JVM中的线程状态，Java 线程状态的改变通常只与**自身显式引入的机制**有关

当进行阻塞IO时，操作系统层面是阻塞，但JVM中该线程仍是“RUNNABLE”

- NEW: 初始状态，线程被创建出来但没有被调用 `start()` 。
- RUNNABLE: 运行状态，线程被调用了 `start()`等待运行的状态。（包括**运行中**和**就绪**）
- BLOCKED：阻塞状态，需要等待锁释放。
- WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。
- TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。
- TERMINATED：终止状态，表示该线程已经运行完毕。

![[Pasted image 20240326205122.png]]

>在操作系统层面，线程有 READY 和 RUNNING 状态；而在 JVM 层面，只能看到 RUNNABLE 状态，所以 Java 系统一般将这两个状态统称为 **RUNNABLE（运行中）** 状态 。
>为什么Java不区分？现在系统的线程切换频率很快，区分就不存在意义了

## 什么是线程上下文切换

线程在执行过程中会有自己的运行条件和状态（也称上下文），比如上文所说到过的程序计数器，栈信息等。

保存当前线程的上下文，留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的 **上下文切换**。

## 程序死锁

程序死锁情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止

死锁的四个必要条件：

1. 互斥条件：该资源任意一个时刻只由一个线程占用。
2. 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
3. 不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. 循环等待条件:若干线程之间形成一种头尾相接的循环等待资源关系。

### 如何预防死锁

破坏死锁的必要条件：
- **破坏请求与保持条件**：一次性申请所有的资源。
- **破坏不剥夺条件**：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
- **破坏循环等待条件**：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。

### 如何避免死锁

避免死锁就是在资源分配时，借助于算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。

## sleep()和wait()
二者都可以暂停线程的运行

- **`sleep()` 方法没有释放锁，而 `wait()` 方法释放了锁** 。
- `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify()`或者 `notifyAll()` 方法。`sleep()`方法执行完成后，线程会自动苏醒，或者也可以使用 `wait(long timeout)` 超时后线程会自动苏醒。
- `sleep()` 是 `Thread` 类的静态本地方法，`wait()` 则是 `Object` 类的本地方法。为什么这样设计呢？下一个问题就会聊到。

### 为什么wait()方法不定义在Thread中

因为线程等待和线程调度是两个不同的概念。`wait()` 方法用于在对象上等待，而不是线程本身。

线程可以调用 `wait()` 方法使自己进入等待状态，这个等待状态是针对某个对象的。

### 为什么 sleep() 方法定义在Thread 

因为 `sleep()` 是让当前线程暂停执行，不涉及到对象类，也不需要获得对象锁。

## 可以直接调用Thread 类的 run 方法吗

不可以

new 一个 `Thread`，线程进入新建状态而不是就绪状态

**调用 `start()` 方法方可启动线程并使线程进入就绪状态，直接执行 `run()` 方法的话不会以多线程的方式执行**

## volatile关键字

`volatile` 关键字：
- 可以保证变量的可见性
- 可以防止指令重排序 

> `volatile` 关键字能保证数据的可见性，但不能保证数据的原子性。`synchronized` 关键字两者都能保证。

双重检验锁方式实现单例模式时，单例对象需要加`volatile` 关键字，否则多线程环境下会导致一个线程获得还没有初始化的实例

## 乐观锁和悲观锁

### 悲观锁

悲观锁总是假设最坏的情况，每次在获取资源操作的时候都会上锁，**共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**。

Java 中`synchronized`和`ReentrantLock`等独占锁就是悲观锁思想的实现

高并发的场景下，激烈的锁竞争会造成线程阻塞，大量阻塞线程会导致系统的上下文切换，增加系统的性能开销。并且，悲观锁还可能会存在死锁问题，影响代码的正常运行。

### 乐观锁

乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了（具体方法可以使用版本号机制或 CAS 算法）。

在 Java 中`java.util.concurrent.atomic`包下面的原子变量类（比如`AtomicInteger`、`LongAdder`）就是使用了乐观锁的一种实现方式 **CAS** 实现的。

- 悲观锁通常多用于写比较多的情况（多写场景，竞争激烈），这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。
- 乐观锁通常多用于写比较少的情况（多读场景，竞争较少），这样可以避免频繁加锁影响性能。乐观锁主要针对的对象是`单个共享变量`

### 如何实现乐观锁

#### 版本号机制

一般是在数据表中加上一个数据版本号 `version` 字段，表示数据被修改的次数。当数据被修改时，`version` 值会加一。当线程 A 要更新数据值时，在读取数据的同时也会读取 `version` 值，在提交更新时，若刚才读取到的 version 值为当前数据库中的 `version` 值相等时才更新，否则重试更新操作，直到更新成功。

#### CAS算法

CAS 的全称是 **Compare And Swap（比较与交换）**,CAS 的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。

CAS 是一个原子操作，底层依赖于一条 CPU 的原子指令。

CAS 涉及到三个操作数：
- **V**：要更新的变量值(Var)
- **E**：预期值(Expected)
- **N**：拟写入的新值(New)
当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新(允许再次尝试)。

Java 语言并没有直接实现 CAS，CAS 相关的实现是通过 C++ 内联汇编的形式实现的（JNI 调用）。因此， CAS 的具体实现和操作系统以及 CPU 都有关系。

#### CAS算法存在的问题

##### ABA问题

如果一个变量 V 初次读取的时候是 A 值，并且在准备赋值的时候检查到它仍然是 A 值，但是在这段时间它的值可能被改为其他值，然后又改回 A，那 CAS 操作就会误认为它从来没有被修改过。这个问题被称为 CAS 操作的 **"ABA"问题。**

ABA 问题的解决思路是在变量前面追加上**版本号或者时间戳**。

##### 循环开销时间大

CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给 CPU 带来非常大的执行开销。

> 自旋操作是指线程在等待某个条件满足时不立即进入阻塞状态，而是通过循环反复检查条件是否满足的一种技术。

##### 只能保证一个共享变量的原子操作

CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。

从 JDK 1.5 开始，提供了`AtomicReference`类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行 CAS 操作。所以可以使用锁或者利用`AtomicReference`类把多个共享变量合并成一个共享变量来操作。

## synchronized关键字

`synchronized` 是 Java 中的一个关键字，翻译成中文是同步的意思，主要解决的是多个线程之间访问资源的同步性，可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

 Java 早期版本中，`synchronized` 属于 **重量级锁**，依赖于操作系统的`Mutex Lock` 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。

在 Java 6 之后， `synchronized` 引入了大量的优化如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销，这些优化让 `synchronized` 锁的效率提升了很多。

### 使用synchronized

 1. 修饰实例方法：给当前对象实例加锁，进入同步代码前要获得 **当前对象实例的锁** 。
 2. 修饰静态方法：给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 **当前 class 的锁**。
 3. 修饰代码块：对括号里指定的对象/类加锁：
	- `synchronized(object)` 表示进入同步代码库前要获得 **给定对象的锁**。
	- `synchronized(类.class)` 表示进入同步代码前要获得 **给定 Class 的锁**

> 静态 `synchronized` 方法和非静态 `synchronized` 方法之间的调用不互斥！因为获取的不是同一个锁

构造方法本身就是线程安全的，**不能使用 synchronized 关键字修饰。**

> 线程试图获取锁也就是获取 **对象监视器 `monitor`** 的持有权。
> 在 Java 虚拟机(HotSpot)中，Monitor 是基于 C++实现的，由`ObjectMonitor`实现的。每个对象中都内置了一个 `ObjectMonitor`对象。

## ReentrantLock 

### ReentrantLock 是什么

`ReentrantLock` 实现了 `Lock` 接口，是一个可重入且独占式的锁，和 `synchronized` 关键字类似。不过，`ReentrantLock` 更灵活、更强大，增加了轮询、超时、中断、公平锁和非公平锁等高级功能。

```Java
public class ReentrantLock implements Lock, java.io.Serializable {}
```

`ReentrantLock` 里面有一个内部类 `Sync`，`Sync` 继承 AQS（`AbstractQueuedSynchronizer`），添加锁和释放锁的大部分操作实际上都是在 `Sync` 中实现的。`Sync` 有公平锁 `FairSync` 和非公平锁 `NonfairSync` 两个子类。

 `ReentrantLock` 的底层就是由 [[Java并发#AQS|AQS]]  来实现的。

### 公平锁和非公平锁

- 公平锁按照申请顺序获得锁，性能差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。
- 非公平锁按照随机或其他优先级获得锁，性能更好，但可能会导致某些线程永远无法获取到锁。

### synchronized和ReentrantLock的区别

- 二者都是重入锁，JDK 提供的所有现成的 `Lock` 实现类，包括 `synchronized` 关键字锁都是可重入的。

>重入锁也叫递归锁，指的是线程可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果是不可重入锁的话，就会造成死锁。

- synchronized 依赖于 JVM，而 ReentrantLock 依赖于 API

- 相比`synchronized`，`ReentrantLock`增加了一些高级功能。主要来说主要有三点：
	1. 等待可中断
	2. 可实现公平锁
	3. 可实现选择性通知（锁可以绑定多个条件）：需要借助于`Condition`接口与`newCondition()`方法

### 可中断锁和不可中断锁

- 可中断锁：获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理。`ReentrantLock` 就属于是可中断锁。
- 不可中断锁：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。`synchronized` 就属于是不可中断锁。

## ReentrantReadWriteLock #不重要 

### ReentrantReadWriteLock是什么

`ReentrantReadWriteLock` 实现了 `ReadWriteLock` ，是一个可重入的读写锁，既可以保证多个线程同时读的效率，同时又可以保证有写入操作时的线程安全。

`ReentrantReadWriteLock` 其实是两把锁，一把是 `WriteLock` (写锁)，一把是 `ReadLock`（读锁） 。读锁是共享锁，写锁是独占锁。读锁可以被同时读，可以同时被多个线程持有，而写锁最多只能同时被一个线程持有。

`ReentrantReadWriteLock`特点：
- 底层也是基于 [[Java并发#AQS|AQS]] 实现的。
- 支持公平锁和非公平锁，默认时非公平锁
- 适合读多写少的情况

>一般锁进行并发控制的规则：读读互斥、读写互斥、写写互斥。
>读写锁进行并发控制的规则：读读不互斥、读写互斥、写写互斥（只有读读不互斥）。

### 共享锁和独占锁的区别

- **共享锁**：一把锁可以被多个线程同时获得。
- **独占锁**：一把锁只能被一个线程获得。

### 线程持有读锁还能获取写锁吗？

**自己的总结**：有读锁被占用（不管自己还是其他线程），写锁都不能被获取；写锁被占用，只有持有写锁的线程可以继续获取读锁

- 在线程持有读锁的情况下，该线程不能取得写锁(因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有)。
- 在线程持有写锁的情况下，**该线程**可以继续获取读锁（获取读锁时如果发现写锁被**其他线程**占用会获取失败）。

>这种规则保证了在读写锁的使用过程中，不会出现读-写锁之间的相互等待情况，从而避免了死锁的发生。同时，这也符合读写锁的设计目的，即允许多个线程同时读取共享资源，但只允许单个线程写入共享资源，从而提高了并发读取的效率。——GPT

### 读锁为什么不能升级为写锁

写锁可以降级为读锁，但是读锁却不能升级为写锁。这是因为读锁升级为写锁会引起线程的争夺，毕竟写锁属于是独占锁，这样的话，会影响性能。

另外，还可能会有死锁问题发生。举个例子：假设两个线程的读锁都想升级写锁，则需要对方都释放自己锁，而双方都不释放，就会产生死锁。

## StampedLock #不重要 

### StampedLock是什么

`StampedLock` 是 JDK 1.8 引入的性能更好的读写锁，不可重入且不支持条件变量 `Condition`

不同于一般的 `Lock` 类，`StampedLock` 并不是直接实现 `Lock`或 `ReadWriteLock`接口，而是基于 **CLH 锁** 独立实现的（ [[Java并发#AQS|AQS]] 也是基于它）。

`StampedLock` 提供了三种模式的读写控制模式：读锁、写锁和乐观读。

`StampedLock` 提供了三种模式的读写控制模式：读锁、写锁和乐观读。

- **写锁**：独占锁，一把锁只能被一个线程获得。当一个线程获取写锁后，其他请求读锁和写锁的线程必须等待。类似于 `ReentrantReadWriteLock` 的写锁，不过这里的写锁是不可重入的。
- **读锁** （悲观读）：共享锁，没有线程获取写锁的情况下，多个线程可以同时持有读锁。如果己经有线程持有写锁，则其他线程请求获取该读锁会被阻塞。类似于 `ReentrantReadWriteLock` 的读锁，不过这里的读锁是不可重入的。
- **乐观读**：允许多个线程获取乐观读以及读锁。同时允许一个写线程获取写锁。

### StampedLock 性能为什么更好

相比于传统读写锁多出来的乐观读是`StampedLock`比 `ReadWriteLock` 性能更好的关键原因。`StampedLock` 的乐观读允许一个写线程获取写锁，所以不会导致所有写线程阻塞，也就是当读多写少的时候，写线程有机会获取写锁，减少了线程饥饿的问题，吞吐量大大提高。

## Atomic 原子类

原子类说简单点就是具有原子/原子操作特征的类。

## ThreadLocal

### ThreadLocal有什么用

通常情况下，我们创建的变量可以被任何一个线程访问并修改的。

`ThreadLocal`类可以让每个线程绑定自己的值，可以将`ThreadLocal`类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。

如果创建了一个`ThreadLocal`变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是`ThreadLocal`变量名的由来。他们可以使用 `get()` 和 `set()` 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。

### ThreadLocal 原理

`Thread` 类中有一个 `threadLocals` 和 一个 `inheritableThreadLocals` 变量，它们都是 `ThreadLocalMap` 类型的变量，`ThreadLocalMap` 理解为`ThreadLocal` 类实现的定制化的 `HashMap`

**最终的变量是放在了当前线程的 `ThreadLocalMap` 中，并不是存在 `ThreadLocal` 上，`ThreadLocal` 可以理解为只是`ThreadLocalMap`的封装，传递了变量值。**

**每个`Thread`中都具备一个`ThreadLocalMap`，而`ThreadLocalMap`可以存储以`ThreadLocal`为 key ，Object 对象为 value 的键值对。**

### ThreadLocal内存泄露问题

`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用，而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。

这样`ThreadLocalMap` 就会出现key为null 的 Entry，导致value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。

`ThreadLocalMap` 实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后最好手动调用`remove()`方法

## 线程池

### 线程池是什么

线程池就是管理一系列线程的资源池。当有任务要处理时，直接从线程池中获取线程来处理，处理完之后线程并不会立即被销毁，而是等待下一个任务。

### 为什么要使用线程池

**线程池**提供了一种限制和管理资源（包括执行一个任务）的方式。 每个**线程池**还维护一些基本统计信息，例如已完成任务的数量。

使用线程池的好处：
- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 

### 如何创建线程池

1. **通过`ThreadPoolExecutor`构造函数来创建（推荐）。**
2. **通过 `Executor` 框架的工具类 `Executors` 来创建。**

### 为什么不推荐使用内置线程池

Java 中的内置线程池是通过 `Executors` 类提供的静态方法来创建的

`Executors` 返回线程池对象的弊端如下：

- **`FixedThreadPool` 和 `SingleThreadExecutor`**:使用的是无界的 `LinkedBlockingQueue`，任务队列最大长度为 `Integer.MAX_VALUE`,可能堆积大量的请求，从而导致 OOM。
- **`CachedThreadPool`**:使用的是同步队列 `SynchronousQueue`, 允许创建的线程数量为 `Integer.MAX_VALUE` ，如果任务数量过多且执行速度较慢，可能会创建大量的线程，从而导致 OOM。
- **`ScheduledThreadPool` 和 `SingleThreadScheduledExecutor`**:使用的无界的延迟阻塞队列`DelayedWorkQueue`，任务队列最大长度为 `Integer.MAX_VALUE`,可能堆积大量的请求，从而导致 OOM。

通过 `ThreadPoolExecutor` 构造函数的方式可以更加明确线程池的运行规则，规避资源耗尽的风险

### 线程池常见参数

**`ThreadPoolExecutor` 3 个最重要的参数：**
- **`corePoolSize` :** 核心线程数，表示线程池中保持存活的线程数，即使它们处于空闲状态。当有新的任务提交时，线程池会优先创建核心线程来执行任务，直到达到核心线程数。
- **`maximumPoolSize` :** 最大线程数，表示线程池中允许存在的最大线程数。当任务队列已满并且核心线程数已经达到最大时，线程池会创建新的线程，直到达到最大线程数。
- **`workQueue`:** 任务队列，用于保存待执行的任务。线程池中的线程会从任务队列中取出任务并执行。

`ThreadPoolExecutor`其他常见参数 :
- **`keepAliveTime`**:线程空闲时间，表示非核心线程在空闲状态下的存活时间。当线程池中的线程数量大于核心线程数，并且空闲时间超过该值时，线程池回收线程时，会对核心线程和非核心线程一视同仁，空闲线程将被销毁，直到线程池中的线程数不超过核心线程数为止。
- **`unit`** : `keepAliveTime` 参数的时间单位。
- **`threadFactory`** :线程工厂，用于创建新的线程。可以通过自定义线程工厂来设置线程的名称、优先级等属性。
- **`handler`** :饱和策略（拒绝策略）。用于指定当任务队列已满并且线程池中的线程数已达到最大值时，如何处理新提交的任务。

### 线程池的饱和策略有哪些

- **`ThreadPoolExecutor.AbortPolicy`：** 抛出 `RejectedExecutionException`来拒绝新任务的处理。
- **`ThreadPoolExecutor.CallerRunsPolicy`：** 将任务交给提交任务的线程来执行。换句话说，当任务被拒绝执行时，线程池会将任务返回给调用者，由调用者所在的线程来执行该任务，如果执行程序已关闭，则会丢弃该任务。但是，如果提交任务的线程本身是一个繁忙的线程，可能会导致调用者线程也变得繁忙，进而影响系统的整体性能。
- **`ThreadPoolExecutor.DiscardPolicy`：** 不处理新任务，直接丢弃掉。
- **`ThreadPoolExecutor.DiscardOldestPolicy`：** 此策略将丢弃最早的未处理的任务请求。

### 线程池常用的阻塞队列

不同的线程池会选用不同的阻塞队列：
- 容量为 `Integer.MAX_VALUE` 的 `LinkedBlockingQueue`（无界队列）：`FixedThreadPool` 和 `SingleThreadExector` 。`FixedThreadPool`最多只能创建核心线程数的线程（核心线程数和最大线程数相等），`SingleThreadExector`只能创建一个线程（核心线程数和最大线程数都是 1），二者的任务队列永远不会被放满。
- `SynchronousQueue`（同步队列）：`CachedThreadPool` 。`SynchronousQueue` 没有容量，不存储元素，目的是保证对于提交的任务，如果有空闲线程，则使用空闲线程来处理；否则新建一个线程来处理任务。也就是说，`CachedThreadPool` 的最大线程数是 `Integer.MAX_VALUE` ，可以理解为线程数是可以无限扩展的，可能会创建大量线程，从而导致 OOM。
- `DelayedWorkQueue`（延迟阻塞队列）：`ScheduledThreadPool` 和 `SingleThreadScheduledExecutor` 。`DelayedWorkQueue` 的内部元素并不是按照放入的时间排序，而是会按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构，可以保证每次出队的任务都是当前队列中执行时间最靠前的。`DelayedWorkQueue` 添加元素满了之后会自动扩容原来容量的 1/2，即永远不会阻塞，最大扩容可达 `Integer.MAX_VALUE`，所以最多只能创建核心线程数的线程。

### 线程池处理流程

![[Pasted image 20240327150044.png]]

### 线程池命名

1. **利用 guava 的 `ThreadFactoryBuilder`**
2. **自己实现 `ThreadFactory`。**

### 如何设置线程池大小

#### 简单公式

- **CPU 密集型任务(N+1)**：N（CPU 核心数）
- **I/O 密集型任务(2N)**

#### 严谨计算

`最佳线程数 = N（CPU 核心数）∗（1+WT（线程等待时间）/ST（线程计算时间））`，其中 `WT（线程等待时间）=线程运行总时间 - ST（线程计算时间）`。

#### 动态修改线程池参数

[Java线程池实现原理及其在美团业务中的实践 - 美团技术团队 (meituan.com)](https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html)

### 如何设计一个能根据任务优先级来执行的线程池

可以使用 `PriorityBlockingQueue`，`PriorityBlockingQueue` 是一个支持优先级的无界阻塞队列，可以看作是线程安全的 `PriorityQueue`。

实现对任务的排序，传入其中的任务必须是具备排序能力的，方式有两种：
- 提交到线程池的任务实现 `Comparable` 接口，并重写 `compareTo` 方法来指定任务之间的优先级比较规则。
- 创建 `PriorityBlockingQueue` 时传入一个 `Comparator` 对象来指定任务之间的排序规则(推荐)。

存在的问题和风险：
- `PriorityBlockingQueue` 是无界的，可能堆积大量的请求，从而导致 OOM。（可以重写`offer`方法解决）
- 可能会导致饥饿问题，即低优先级的任务长时间得不到执行。
- 由于需要对队列中的元素进行排序操作以及保证线程安全（并发控制采用的是可重入锁 `ReentrantLock`），因此会降低性能。

## Future类

### Future 类是什么

`Future` 类是异步思想的典型运用，使用它可以在a线程中启动一个任务，在b线程中执行任务获取执行结果，并将结果返回给a线程。

`Future<V>`接口表示一个未来可能会返回的结果，定义的方法有：
- `get()`：获取结果（可能会等待）
- `get(long timeout, TimeUnit unit)`：获取结果，但只等待指定的时间；
- `cancel(boolean mayInterruptIfRunning)`：取消当前任务；
- `isDone()`：判断任务是否已完成。

### callable 和 Future有什么关系

`Callable` 和 `Future` 是 Java 并发编程中两个相关的接口，它们通常一起使用来实现异步任务的执行和获取结果

`FutureTask` 提供了 `Future` 接口的基本实现，常用来封装 `Callable` 和 `Runnable`。`ExecutorService.submit()` 方法返回的其实就是 `Future` 的实现类 `FutureTask` 。

通常情况下，将一个 `Callable` 对象提交给 `ExecutorService` 进行执行，`ExecutorService` 会返回一个 `Future` 对象，通过这个 `Future` 对象可以获取任务的执行结果。

### CompletableFuture

`CompletableFuture` 除了提供了更为好用和强大的 `Future` 特性之外，还提供了函数式编程、异步任务编排组合（可以将多个异步任务串联起来，组成一个完整的链式调用）等能力。

## AQS

AQS 的全称为 `AbstractQueuedSynchronizer` ，即抽象队列同步器，是一个抽象类，主要用来构建锁和同步器。

### AQS原理

AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 **CLH 队列锁** 实现的，即将暂时获取不到锁的线程加入到队列中。

CLH(Craig,Landin,and Hagersten) 队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。在 CLH 同步队列中，一个节点表示一个线程，它保存着线程的引用（thread）、 当前节点在队列中的状态（waitStatus）、前驱节点（prev）、后继节点（next）。

![[Pasted image 20240327165547.png]]

AQS(`AbstractQueuedSynchronizer`)的核心原理图：
![[Pasted image 20240327165742.png]]

## Semaphore类

`Semaphore`(信号量)可以用来控制同时访问特定资源的线程数量。

`Semaphore` 有两种模式：。

- **公平模式：** 调用 `acquire()` 方法的顺序就是获取许可证的顺序，遵循 FIFO；
- **非公平模式：** 抢占式的。

`Semaphore` 通常用于那些资源有明确访问数量限制的场景比如限流（仅限于单机模式，实际项目中推荐使用 Redis +Lua 来做限流）

### Semaphore 的原理

`Semaphore` 是共享锁的一种实现，它默认构造 AQS 的 `state` 值为 `permits`，你可以将 `permits` 的值理解为许可证的数量，只有拿到许可证的线程才能执行。

## CountDownLatch


## CyclicBarrier

## ## 并发集合类

| interface | non-thread-safe         | thread-safe                              |     |     |
| --------- | ----------------------- | ---------------------------------------- | --- | --- |
| List      | ArrayList               | CopyOnWriteArrayList                     |     |     |
| Map       | HashMap                 | ConcurrentHashMap                        |     |     |
| Set       | HashSet / TreeSet       | CopyOnWriteArraySet                      |     |     |
| Queue     | ArrayDeque / LinkedList | ArrayBlockingQueue / LinkedBlockingQueue |     |     |
| Deque     | ArrayDeque / LinkedList | LinkedBlockingDeque                      |     |     |
> 使用这些并发集合与使用非线程安全的集合类完全相同。

### 阻塞队列

**阻塞队列（BlockingQueue）** 是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。

